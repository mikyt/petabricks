#ifndef NWKDE_PBCC
#define NWKDE_PBCC

#include "../simple/macros.h"
#include "../simple/reduce.pbcc"
#include "nwkde.h"
#include "nwkdeGenerators.pbcc"
#include "nwkdeMetric.pbcc"
#include "utils.pbcc"

%{

/* wrap relative difference into [-180,180]
 * do most of the arithmetic in integers for speed
 * P360 and M360 indicate "plus 360" and "minus 360" */
inline ElementT wrapWindDirDiff(ElementT diff)
{
    /* add 360 *before* cast to round towards -INF instead of towards 0 */
    int diffIntP360 = (int) (diff + 360);

    /* add 180 to ensure modulo result is positive */
    int diffIntWrapP360 = ((diffIntP360 + 180) % 360) + 180;

    return diff + (diffIntWrapP360 - diffIntP360);
}

%}

transform NWKDECheckInputs
from TRAINDATA[m,n], TRAININDICES[l], TRAINVARINDEX[p], TRAINTIMEOFFSET[p],
     TESTDATA[m2,n2], TESTINDICES[q], TESTVARINDEX[p], TESTTIMEOFFSET[p],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET
to INPUTSCHECKED
{
    INPUTSCHECKED
    from (TRAININDICES trainIndices,
          TRAINVARINDEX trainVarIndex,
          TRAINTIMEOFFSET trainTimeOffset,
          TESTINDICES testIndices,
          TESTVARINDEX testVarIndex,
          TESTTIMEOFFSET testTimeOffset,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset)
    {
        ElementT min, max, min2, max2;

        findMinAndMax(&min, &max, trainVarIndex);
        fprintf(stderr, "trainVarIndex range: (%g, %g)\n", min, max);
        if (min < 0 || max > m) {
            fprintf(stderr, "trainVarIndex out of bounds: (%d, %d)\n", 0, m);
            PetabricksRuntime::abort();
        }

        fprintf(stderr, "outputVarIndex: %g\n", outputVarIndex);
        if (outputVarIndex < 0 || outputVarIndex > m) {
            fprintf(stderr, "outputVarIndex out of bounds: (%d, %d)\n", 0, m);
            PetabricksRuntime::abort();
        }

        findMinAndMax(&min, &max, testVarIndex);
        fprintf(stderr, "testVarIndex range: (%g, %g)\n", min, max);
        if (min < 0 || max > m2) {
            fprintf(stderr, "testVarIndex out of bounds: (%d, %d)\n", 0, m2);
            PetabricksRuntime::abort();
        }

        findMinAndMax(&min, &max, trainIndices);
        findMinAndMax(&min2, &max2, trainTimeOffset);
        fprintf(stderr, "trainIndices + trainTimeOffset range: (%g, %g)\n",
               min + min2, max + max2);
        if (min + min2 < 0 || max + max2 > n) {
            fprintf(stderr, "trainIndices + trainTimeOffset out of bounds: (%d, %d)\n",
                   0, n);
            PetabricksRuntime::abort();
        }

        fprintf(stderr, "trainIndices + outputTimeOffset range: (%g, %g)\n",
               min + outputTimeOffset, max + outputTimeOffset);
        if (min + outputTimeOffset < 0 || max + outputTimeOffset > n) {
            fprintf(stderr, "trainIndices + outputTimeOffset out of bounds: (%d, %d)\n",
                   0, n);
            PetabricksRuntime::abort();
        }

        findMinAndMax(&min, &max, testIndices);
        findMinAndMax(&min2, &max2, testTimeOffset);
        fprintf(stderr, "testIndices + testTimeOffset range: (%g, %g)\n",
               min + min2, max + max2);
        if (min + min2 < 0 || max + max2 > n2) {
            fprintf(stderr, "testIndices + testTimeOffset out of bounds: (%d, %d)\n",
                   0, n2);
            PetabricksRuntime::abort();
        }
    }
}

/*  TRAINDATA - block of data: n time slices, m variables per time slice
    TRAININDICES - l time indices into TRAINDATA to use for training

    TESTDATA - block of data: n2 time slices, m2 variables per time slice
    TESTINDICES - q indices into TESTDATA to evaluate the regression

    WRAPFLAGS - indicates whether TRAINDATA column corresponds to a wind
                direction \in [0, 360]
    KERNELWIDTHS - width of the kernel function to use for a data column

    For each time index in TRAININDICES or TESTINDICES, we associate
    a p-dim vector of predictors for use during regression.  The
    TRAINVARINDEX array contains the column index (into TRAINDATA) of
    the variable to use for each predictor.  The TRAINTIMEOFFSET array
    contains the time offset relative to the current time index.  In this way,
    we can build predictor vectors that contain overlapping data for
    different time indices.  Similarly, TESTVARINDEX and TESTTIMEOFFSET
    specify the predictor vector to use when computing the regression output.

    OUTPUTVARINDEX - which variable in TRAINDATA for output
    OUTPUTTIMEOFFSET - time offset from trainIndex in TRAINDATA for output
    TRAINMASKWIDTH - width of training mask.  This tells the transform to
                     omit training indices less than TRAINMASKWIDTH
                     indices of the test index when computing the regression.
                     Note: to be used when TESTDATA is equal to TRAINDATA.
                     May set to 0 (no mask effect) if TESTDATA is separate
                     from TRAINDATA.

    SQDIFFS - squared differences for each predictor for each train-test
              point pair
    WEIGHTS - weights computed with Gaussian kernel function for each
              train-test point pair
    PARTIALS - weighted output partial sums
*/

#define INCLUDE_METHOD2
#define INCLUDE_METHOD3

transform NWKDEBase
from TRAINDATA[m,n], WRAPFLAGS[m], KERNELWIDTHS[m],
     TRAININDICES[l], TRAINVARINDEX[p], TRAINTIMEOFFSET[p],
     TESTDATA[m2,n2],
     TESTINDICES[q], TESTVARINDEX[p], TESTTIMEOFFSET[p],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET,
     TRAINMASKWIDTH
to RESULT[q]
through INITFLAGS[l], SKIPINDEXFLAGS[l], SQDIFFS[p,l,q], WEIGHTS[l,q], PARTIALS[l,q]
{

#ifdef INCLUDE_METHOD1 // TODO: This method seems to confuse the scheduler

    /* METHOD 1: compute PARTIALS by exposing the most fine-grained
       parallelism.  this method may be less cache-efficient depending on
       execution ordering. */

    // initialize skip index flags to 0
    to   (INITFLAGS.cell(j) initFlag,
          SKIPINDEXFLAGS.cell(j) skipIndexFlag)
    from ()
    {
        skipIndexFlag = 0;
        initFlag = 1;
    }

    // Note: rule depends on initFlag so that skipIndexFlag defaults to 0
    to   (SQDIFFS.cell(i,j,k) sqDiff,
          SKIPINDEXFLAGS.cell(j) skipIndexFlag)
    from (INITFLAGS.cell(j) initFlag,
          TRAINDATA trainData,
          WRAPFLAGS wrapFlags,
          KERNELWIDTHS kernelWidths,
          TRAININDICES.cell(j) trainIndex,
          TRAINVARINDEX.cell(i) trainVarIndex,
          TRAINTIMEOFFSET.cell(i) trainTimeOffset,
          TESTDATA testData,
          TESTINDICES.cell(k) testIndex,
          TESTVARINDEX.cell(i) testVarIndex,
          TESTTIMEOFFSET.cell(i) testTimeOffset)
    {
        IndexT wrapFlag, trainTimeIndex, testTimeIndex;
        ElementT kernelWidth, trainPoint, testPoint, diff;

        wrapFlag    =    wrapFlags.cell(trainVarIndex);
        kernelWidth = kernelWidths.cell(trainVarIndex);

        trainTimeIndex = trainIndex + trainTimeOffset;
        testTimeIndex  =  testIndex +  testTimeOffset;

        trainPoint = trainData.cell(trainVarIndex, trainTimeIndex);
        testPoint  =  testData.cell( testVarIndex,  testTimeIndex);

        // skip this variable if nan is detected in the test point
        if (ISNAN(testPoint)) {
            sqDiff = 0;
            return;
        }

        // skip this training index if nan is detected in the train point
        if (ISNAN(trainPoint)) {
            skipIndexFlag = 1;
            return;
        }

        diff = trainPoint - testPoint;

        if (wrapFlag) {
            diff = wrapWindDirDiff(diff);
        }

        // normalize according to kernel width
        diff /= kernelWidth;

        // return squared difference
        sqDiff = diff * diff;
#ifdef DEBUG
        fprintf(stderr, "method 1:  sqdiff(%d, %d, %d) = %g\n", i, j, k, sqDiff);
#endif
    }

    to (WEIGHTS.cell(j,k) weight)
    from (SQDIFFS.region(0, j,   k,
                         p ,j+1, k+1) sqDiffs,
          TRAININDICES.cell(j) trainIndex,
          TESTINDICES.cell(k) testIndex,
          TRAINMASKWIDTH trainMaskWidth,
          SKIPINDEXFLAGS.cell(j) skipIndexFlag)
    {
        if (!skipIndexFlag &&
            (trainIndex <= testIndex - trainMaskWidth ||
             trainIndex >= testIndex + trainMaskWidth)) {
            ReduceAdd(weight, sqDiffs.slice(2,0).slice(1,0));
            weight = exp(-((ElementT) weight));
        } else {
            weight = 0;
        }
#ifdef DEBUG
        fprintf(stderr, "method 1:  weight(%d, %d) = %g\n", j, k, weight);
#endif
    }

    to (PARTIALS.cell(j,k) partial)
    from (TRAINDATA trainData,
          TRAININDICES.cell(j) trainIndex,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          WEIGHTS.cell(j,k) weight)
    {
        IndexT timeIndex = trainIndex + outputTimeOffset;
        outputVal = trainData.cell(outputVarIndex, timeIndex);
        partial = ISNAN(outputVal) ? 0 : weight * outputVal;
#ifdef DEBUG
        fprintf(stderr, "method 1: partial(%d, %d) = %g\n", j, k, partial);
#endif
    }

    /* METHODS 1 & 2: Once we have the PARTIALS and WEIGHTS, we can compute
       RESULT */

    to (RESULT.cell(k) result)
    from (PARTIALS.row(k) partials,
          WEIGHTS.row(k) weights)
    {
        ElementT totalWeight;
        ReduceAdd1D(result, partials);
        ReduceAdd1D(totalWeight, weights);
        result /= totalWeight;
#ifdef DEBUG
        fprintf(stderr, "Output %d = %g\n", k, result);
#endif // DEBUG
    }

#endif // INCLUDE_METHOD1

#ifdef INCLUDE_METHOD2

    /* METHOD 2: Compute weights and partials directly with one pass through the data */

    to   (PARTIALS.cell(j,k) partial,
          WEIGHTS.cell(j,k) weight)
    from (TRAINDATA trainData,
          WRAPFLAGS wrapFlags,
          KERNELWIDTHS kernelWidths,
          TRAININDICES.cell(j) trainIndex,
          TRAINVARINDEX trainVarIndex,
          TRAINTIMEOFFSET trainTimeOffset,
          TESTDATA testData,
          TESTINDICES.cell(k) testIndex,
          TESTVARINDEX testVarIndex,
          TESTTIMEOFFSET testTimeOffset,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH trainMaskWidth)
    {
        IndexT i, wrapFlag, outputTimeIndex, trainTimeIndex, testTimeIndex;
        ElementT outputVal, kernelWidth, trainPoint, testPoint, diff, sum;

        outputTimeIndex = trainIndex + outputTimeOffset;
        outputVal = trainData.cell(outputVarIndex, outputTimeIndex);

        // skip current training index if it is too close to the test index or
        // if the training output value is a NAN
        if ((trainIndex > testIndex - trainMaskWidth &&
             trainIndex < testIndex + trainMaskWidth) ||
            ISNAN(outputVal)) {
            weight = partial = 0;
            return;
        }

        sum = 0;
        for (i = 0; i < trainVarIndex.count(); ++i) {

            wrapFlag    =    wrapFlags.cell(trainVarIndex.cell(i));
            kernelWidth = kernelWidths.cell(trainVarIndex.cell(i));

            trainTimeIndex = trainIndex + trainTimeOffset.cell(i);
            testTimeIndex  =  testIndex +  testTimeOffset.cell(i);

            trainPoint = trainData.cell(trainVarIndex.cell(i), trainTimeIndex);
            testPoint  =  testData.cell( testVarIndex.cell(i),  testTimeIndex);

            // skip this variable if nan is detected in the test point
            if (ISNAN(testPoint)) {
                continue;
            }

            // skip this training index if nan is detected in the train point
            if (ISNAN(trainPoint)) {
                weight = partial = 0;
                return;
            }

            diff = trainPoint - testPoint;

            if (wrapFlag) {
                diff = wrapWindDirDiff(diff);
            }

            // normalize according to kernel width
            diff /= kernelWidth;

            // return squared difference
            sum += diff * diff;
        }

        weight = exp(-((ElementT) sum));
        partial = weight * outputVal;
#ifdef DEBUG
        fprintf(stderr, "method 2:  weight(%d, %d) = %g\n", j, k, weight);
        fprintf(stderr, "method 2: partial(%d, %d) = %g\n", j, k, partial);
#endif
    }

    /* METHODS 1 & 2: Once we have the PARTIALS and WEIGHTS, we can compute
       RESULT */

    to (RESULT.cell(k) result)
    from (PARTIALS.row(k) partials,
          WEIGHTS.row(k) weights)
    {
        ElementT totalWeight;
        ReduceAdd1D(result, partials);
        ReduceAdd1D(totalWeight, weights);
        result /= totalWeight;
#ifdef DEBUG
        fprintf(stderr, "Output %d = %g\n", k, result);
#endif // DEBUG
    }

#endif // INCLUDE_METHOD2

#ifdef INCLUDE_METHOD3

    /* METHOD 3: Compute results directly with one pass through the data */

    to   (RESULT.cell(k) result)
    from (TRAINDATA trainData,
          WRAPFLAGS wrapFlags,
          KERNELWIDTHS kernelWidths,
          TRAININDICES trainIndices,
          TRAINVARINDEX trainVarIndex,
          TRAINTIMEOFFSET trainTimeOffset,
          TESTDATA testData,
          TESTINDICES.cell(k) testIndex,
          TESTVARINDEX testVarIndex,
          TESTTIMEOFFSET testTimeOffset,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH trainMaskWidth)
    {
        bool skipIndexFlag;
        IndexT i, j, wrapFlag, trainIndex, outputTimeIndex, trainTimeIndex,
               testTimeIndex;
        ElementT outputVal, kernelWidth, trainPoint, testPoint, diff, sum,
                 weight, partial, totalPartial, totalWeight;

        // loop over training points
        totalPartial = totalWeight = 0;
        for (j = 0; j < trainIndices.count(); ++j) {

            trainIndex = trainIndices.cell(j);
            outputTimeIndex = trainIndex + outputTimeOffset;
            outputVal = trainData.cell(outputVarIndex, outputTimeIndex);

            // skip current training index if it is too close to the test
            // index or if the training output value is a NAN
            if ((trainIndex > testIndex - trainMaskWidth &&
                 trainIndex < testIndex + trainMaskWidth) ||
                ISNAN(outputVal)) {
                continue;
            }

            // loop over predictor variables to calculate training weight
            sum = 0;
            skipIndexFlag = false;
            for (i = 0; i < trainVarIndex.count(); ++i) {

                wrapFlag    =    wrapFlags.cell(trainVarIndex.cell(i));
                kernelWidth = kernelWidths.cell(trainVarIndex.cell(i));

                trainTimeIndex = trainIndex + trainTimeOffset.cell(i);
                testTimeIndex  =  testIndex +  testTimeOffset.cell(i);

                trainPoint = trainData.cell(trainVarIndex.cell(i),
                                            trainTimeIndex);
                testPoint  =  testData.cell( testVarIndex.cell(i),
                                             testTimeIndex);

                // skip this variable if nan is detected in the test point
                if (ISNAN(testPoint)) {
                    continue;
                }

                // skip this training index if nan is detected
                if (ISNAN(trainPoint)) {
                    skipIndexFlag = true;
                    break;
                }

                diff = trainPoint - testPoint;

                if (wrapFlag) {
                    diff = wrapWindDirDiff(diff);
                }

                // normalize according to kernel width
                diff /= kernelWidth;

                // return squared difference
                sum += diff * diff;
            }

            if (skipIndexFlag) {
                continue;
            }

            weight = exp(-((ElementT) sum));
            partial = weight * outputVal;

#ifdef DEBUG
            fprintf(stderr, "method 3:  weight(%d, %d) = %g\n", j, k, weight);
            fprintf(stderr, "method 3: partial(%d, %d) = %g\n", j, k, partial);
#endif // DEBUG
            totalWeight += weight;
            totalPartial += partial;
        }

        result = totalPartial / totalWeight;
#ifdef DEBUG
        fprintf(stderr, "Output %d = %g\n", k, result);
#endif // DEBUG
    }
#endif // INCLUDE_METHOD3
}

transform NWKDERecursive
from TRAINDATA[m,n], WRAPFLAGS[m], KERNELWIDTHS[m],
     TRAININDICES[l], TRAINVARINDEX[p], TRAINTIMEOFFSET[p],
     TESTDATA[m2,n2],
     TESTINDICES[q], TESTVARINDEX[p], TESTTIMEOFFSET[p],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET, TRAINMASKWIDTH
to RESULT[q]
tunable recursiveCutoff
{
    to   (RESULT           result)
    from (TRAINDATA        trainData,
          WRAPFLAGS        wrapFlags,
          KERNELWIDTHS     kernelWidths,
          TRAININDICES     trainIndices,
          TRAINVARINDEX    trainVarIndex,
          TRAINTIMEOFFSET  trainTimeOffset,
          TESTDATA         testData,
          TESTINDICES      testIndices,
          TESTVARINDEX     testVarIndex,
          TESTTIMEOFFSET   testTimeOffset,
          OUTPUTVARINDEX   outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH   trainMaskWidth)
    {
        if (q <= MAX(1, recursiveCutoff)) {
            NWKDEBase(result, trainData, wrapFlags, kernelWidths,
                      trainIndices, trainVarIndex, trainTimeOffset,
                      testData, testIndices,
                      testVarIndex, testTimeOffset,
                      outputVarIndex, outputTimeOffset, trainMaskWidth);
            return;
        }

        int mid = q / 2;
        spawn NWKDERecursive(result.region(0, mid),
                       trainData, wrapFlags, kernelWidths,
                       trainIndices, trainVarIndex, trainTimeOffset,
                       testData, testIndices.region(0, mid),
                       testVarIndex, testTimeOffset,
                       outputVarIndex, outputTimeOffset, trainMaskWidth);
        spawn NWKDERecursive(result.region(mid, q),
                       trainData, wrapFlags, kernelWidths,
                       trainIndices, trainVarIndex, trainTimeOffset,
                       testData, testIndices.region(mid, q),
                       testVarIndex, testTimeOffset,
                       outputVarIndex, outputTimeOffset, trainMaskWidth);
        sync;
    }
}

transform NWKDE
from TRAINDATA[M,N], WRAPFLAGS[M], KERNELWIDTHS[M],
     TRAININDICES[L], TRAINVARINDEX[P], TRAINTIMEOFFSET[P],
     TESTDATA[M2,N2],
     TESTINDICES[Q], TESTVARINDEX[P], TESTTIMEOFFSET[P],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET, TRAINMASKWIDTH
to RESULT[Q]
through INPUTSCHECKED
generator NWKDEGenerator3
accuracy_metric NWKDEMetric2
{
    to (RESULT result)
    from (TRAINDATA        trainData,
          WRAPFLAGS        wrapFlags,
          KERNELWIDTHS     kernelWidths,
          TRAININDICES     trainIndices,
          TRAINVARINDEX    trainVarIndex,
          TRAINTIMEOFFSET  trainTimeOffset,
          TESTDATA         testData,
          TESTINDICES      testIndices,
          TESTVARINDEX     testVarIndex,
          TESTTIMEOFFSET   testTimeOffset,
          OUTPUTVARINDEX   outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH   trainMaskWidth)
    {
#ifdef DEBUG
        ElementT ret;
        NWKDECheckInputs(ret, trainData, trainIndices,
                         trainVarIndex, trainTimeOffset,
                         testData, testIndices,
                         testVarIndex, testTimeOffset,
                         outputVarIndex, outputTimeOffset);
#endif
        NWKDERecursive(result, trainData, wrapFlags, kernelWidths,
                       trainIndices, trainVarIndex, trainTimeOffset,
                       testData, testIndices,
                       testVarIndex, testTimeOffset,
                       outputVarIndex, outputTimeOffset, trainMaskWidth);
    }
}

#endif // NWKDE_PBCC
